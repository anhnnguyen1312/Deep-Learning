{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "518h0470_518h0578.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install -r setup.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szn3f9DLwnuS",
        "outputId": "49caee3e-5122-4db2-daf9-b387fa53ab1e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r setup.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from -r setup.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r setup.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r setup.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from -r setup.txt (line 5)) (0.8.1)\n",
            "Collecting path.py\n",
            "  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r setup.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r setup.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->-r setup.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r setup.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r setup.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r setup.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r setup.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r setup.txt (line 3)) (3.0.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (1.42.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (3.17.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (0.37.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (12.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (0.22.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (0.2.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (3.10.0.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r setup.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r setup.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->-r setup.txt (line 4)) (3.1.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (2.1.9)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (0.10.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->-r setup.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->-r setup.txt (line 5)) (0.34.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->-r setup.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->-r setup.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->-r setup.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r setup.txt (line 5)) (2.21)\n",
            "Collecting path\n",
            "  Downloading path-16.2.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: path, path.py\n",
            "Successfully installed path-16.2.0 path.py-12.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from memory_profiler import memory_usage\n",
        "import os\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "\n",
        "import keras.backend as K\n",
        "import librosa\n",
        "import librosa.display\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import figure\n",
        "import gc\n",
        "import librosa as lr\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from librosa.display import specshow\n",
        "from os import path"
      ],
      "metadata": {
        "id": "gCFqL80Npg0o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path='518h0470_518h0578/data/train/'\n",
        "test_data_path='518h0470_518h0578/data/test/'\n",
        "wav_path = '518h0470_518h0578/data/wav/train'\n",
        "wav_path_test = '518h0470_518h0578/data/wav/test'"
      ],
      "metadata": {
        "id": "RvXjrnQP-hdO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_spectrogram(filename,name, file_path):\n",
        "    plt.interactive(False)\n",
        "    clip, sample_rate = librosa.load(filename, sr=None)\n",
        "    fig = plt.figure(figsize=[0.72,0.72])\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.axes.get_xaxis().set_visible(False)\n",
        "    ax.axes.get_yaxis().set_visible(False)\n",
        "    ax.set_frame_on(False)\n",
        "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
        "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
        "    filename  = file_path + name + '.png'\n",
        "    plt.savefig(filename, dpi=400, bbox_inches='tight',pad_inches=0)\n",
        "    plt.close()\n",
        "    fig.clf()\n",
        "    plt.close(fig)\n",
        "    plt.close('all')\n",
        "    del filename,name,clip,sample_rate,fig,ax,S"
      ],
      "metadata": {
        "id": "O_QHqEQo-j1d"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Data_dir=glob(wav_path+\"/*.wav\")\n",
        "\n",
        "for file in Data_dir: \n",
        "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
        "    create_spectrogram(filename,name, train_data_path)\n",
        "    \n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elpviG1B-lwe",
        "outputId": "18b1fcb3-c94e-4b51-b469-6b8ff9414d9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35366"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Test_dir=glob(wav_path_test+\"/*.wav\")\n",
        "\n",
        "for file in Test_dir:\n",
        "    filename,name = file,file.split('/')[-1].split('.')[0]\n",
        "    create_spectrogram(filename,name,test_data_path)\n",
        "\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFZANJzUBCvJ",
        "outputId": "c6abe45c-c626-49d3-83fa-d99df94aaaf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18502"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def append_ext(fn):\n",
        "    return fn.replace(\".wav\",\".png\")\n",
        "\n",
        "# Load du lieu train va test tu file csv\n",
        "traindf=pd.read_csv('518h0470_518h0578/data/train.csv',dtype=str)\n",
        "testdf=pd.read_csv('518h0470_518h0578/data/test.csv',dtype=str)\n",
        "traindf[\"slice_file_name\"]=traindf[\"slice_file_name\"].apply(append_ext)\n",
        "testdf[\"slice_file_name\"]=testdf[\"slice_file_name\"].apply(append_ext)\n",
        "\n",
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
        "print(traindf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lev1A1rIyMKf",
        "outputId": "9eecf8ce-b245-42d9-c69a-7c0d2de3c42e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   slice_file_name    fsID start   end salience fold classID class\n",
            "0         Bac1.png  100263  58.5  62.5        1    5       2   bac\n",
            "1         Bac2.png  100263  60.5  64.5        1    5       2   bac\n",
            "2         Bac3.png  100263    63    67        1    5       2   bac\n",
            "3         Bac4.png  100263  68.5  72.5        1    5       2   bac\n",
            "4         Bac5.png  100263  71.5  75.5        1    5       2   bac\n",
            "5         Hue1.png  100852  80.5  84.5        1    5       1   hue\n",
            "6         Hue2.png  100852   1.5   5.5        1    5       1   hue\n",
            "7         Hue3.png  100852    18    22        1    5       1   hue\n",
            "8         Hue4.png  100852     0     4        1    5       1   hue\n",
            "9         Hue5.png  100852   0.5   4.5        1    5       1   hue\n",
            "10        Nam6.png  100851     5     9        1    5       0   nam\n",
            "11        Nam7.png  100851   5.5   9.5        1    5       0   nam\n",
            "12        Nam1.png  100852   6.5  10.5        2    6       1   nam\n",
            "13        Nam2.png  100853   7.5  11.5        3    7       2   nam\n",
            "14        Nam3.png  100854   8.5  12.5        4    8       3   nam\n",
            "15        Nam4.png  100855   9.5  13.5        5    9       4   nam\n",
            "16        Nam5.png  100856  10.5  14.5        6   10       5   nam\n",
            "17        Hue6.png  100263  71.5  75.5        1    5       2   hue\n",
            "18        Bac6.png  100264  72.5  76.5        2    6       3   bac\n",
            "19        Bac7.png  100265  73.5  77.5        3    7       4   bac\n",
            "20        Hue7.png  100263  71.5  75.5        1    5       2   hue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=traindf,\n",
        "    directory=train_data_path,\n",
        "    x_col=\"slice_file_name\",\n",
        "    y_col=\"class\",\n",
        "    subset=\"training\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(64,64))\n",
        "print(train_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUd7_lkuEaAx",
        "outputId": "1f95872b-e50e-4702-d4d0-4fc3eb1e5a07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16 validated image filenames belonging to 3 classes.\n",
            "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7fef6113ae50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_generator=datagen.flow_from_dataframe(\n",
        "    dataframe=traindf,\n",
        "    directory=train_data_path,\n",
        "    x_col=\"slice_file_name\",\n",
        "    y_col=\"class\",\n",
        "    subset=\"validation\",\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    target_size=(64,64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wc1cxqezEbEA",
        "outputId": "1e1852e5-36e9-4f57-9166-496835753d9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "B4I30KvjMcfv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(64,64,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
        "                       tf.keras.metrics.FalseNegatives()])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-6a7nQ9zJpJ",
        "outputId": "999c1ab5-8426-4d90-e0b9-11023cd47369"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64, 64, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 62, 64)        18496     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 62, 62, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 31, 31, 64)        36928     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 31, 31, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 29, 29, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2359808   \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,676,035\n",
            "Trainable params: 2,676,035\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "print(STEP_SIZE_TRAIN)\n",
        "print(train_generator)"
      ],
      "metadata": {
        "id": "KAsOpLfHEmLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b921e55-9928-4856-d716-8e5a3301c3e1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7fef6113ae50>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "print(valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDU-Wh8CwbyB",
        "outputId": "ff5c8f17-0425-46d4-b99b-9114439fe9a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras_preprocessing.image.dataframe_iterator.DataFrameIterator object at 0x7feed27d6190>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "history=model.fit(train_generator, epochs=10, validation_data=valid_generator) \n",
        "model.save(\"model.h5\");\n",
        "with open('model_indices.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_generator.class_indices, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hu0N2bhDPsE",
        "outputId": "6ccb736b-d47e-4bd3-ddf6-53b8b4bbb212"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6995 - binary_accuracy: 0.6667 - false_negatives: 16.0000 - val_loss: 0.7190 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.6350 - binary_accuracy: 0.6667 - false_negatives: 16.0000 - val_loss: 0.8511 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 0.5865 - binary_accuracy: 0.6875 - false_negatives: 11.0000 - val_loss: 0.9844 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 625ms/step - loss: 0.6197 - binary_accuracy: 0.6458 - false_negatives: 10.0000 - val_loss: 0.8657 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 615ms/step - loss: 0.5808 - binary_accuracy: 0.6875 - false_negatives: 9.0000 - val_loss: 0.7895 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 617ms/step - loss: 0.5566 - binary_accuracy: 0.7708 - false_negatives: 10.0000 - val_loss: 0.7889 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 620ms/step - loss: 0.5722 - binary_accuracy: 0.7917 - false_negatives: 9.0000 - val_loss: 0.8243 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 634ms/step - loss: 0.5346 - binary_accuracy: 0.8333 - false_negatives: 6.0000 - val_loss: 0.9180 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 610ms/step - loss: 0.5281 - binary_accuracy: 0.8542 - false_negatives: 4.0000 - val_loss: 0.9878 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 622ms/step - loss: 0.5470 - binary_accuracy: 0.8333 - false_negatives: 4.0000 - val_loss: 0.9273 - val_binary_accuracy: 0.6667 - val_false_negatives: 5.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "def append_ext(fn):\n",
        "    return fn.replace(\".wav\",\".png\")\n",
        "\n",
        "# Load du lieu test\n",
        "testdf=pd.read_csv('518h0470_518h0578/data/test.csv',dtype=str)\n",
        "testdf[\"slice_file_name\"]=testdf[\"slice_file_name\"].apply(append_ext)\n",
        "test_data_path='518h0470_518h0578/data/test/'\n",
        "\n",
        "# Khoi tao du lieu test\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "    dataframe=testdf,\n",
        "    directory=test_data_path,\n",
        "    x_col=\"slice_file_name\",\n",
        "    y_col=None,\n",
        "    batch_size=32,\n",
        "    seed=42,\n",
        "    shuffle=False,\n",
        "    class_mode=None,\n",
        "    target_size=(64,64))\n",
        "\n",
        "# TInh so buoc test\n",
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "\n",
        "# Tien hanh predict\n",
        "test_generator.reset()\n",
        "\n",
        "# Load model da train\n",
        "model = load_model('model.h5')\n",
        "pred = model.predict(test_generator,verbose=1)\n",
        "\n",
        "\n",
        "# Lay class predict probality lon nhat\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "# Load class name tu file\n",
        "with open('model_indices.pickle', 'rb') as handle:\n",
        "    labels = pickle.load(handle)\n",
        "\n",
        "# HIen thi ket qua predict ra man hinh\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "print(\"Prediction values= \",predictions[0:15])\n",
        "print(\"Real values=\",testdf.head(15)[\"class\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIIABGff3qq1",
        "outputId": "050fe8f3-2312-402e-e4b4-f856648d36e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9 validated image filenames.\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "Prediction values=  ['nam', 'hue', 'hue', 'hue', 'hue', 'hue', 'hue', 'nam', 'nam']\n",
            "Real values= 0    nam\n",
            "1    bac\n",
            "2    bac\n",
            "3    bac\n",
            "4    hue\n",
            "5    hue\n",
            "6    hue\n",
            "7    nam\n",
            "8    nam\n",
            "Name: class, dtype: object\n"
          ]
        }
      ]
    }
  ]
}